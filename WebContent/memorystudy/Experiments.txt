This fle summarises experiments on question generation and their results.
-------------------------------
Experiment - 1:
See memorystudy/entityexperiment.jsp
If an entity is followed by its co-referring mention, then that is a signal that the entity is not casual mention.
Problems/Conclusions:
TBF
-------------------------------
Experiment - 2:
See memorystudy/entityexperiment_2.jsp
The entities mentioned in sentences with one of the words thar are some form of "I", "You" are important.
Problems/Conclusions
1. This relatively did better than experiment 1.
   But, it may not be just about, selecting the right entities to ask question on.
**TBF**

-------------------------------
Experiment - 3:
See memorystudy/entityexperiment_3.jsp
Most verbs are representative of the event.
We define events as phrases that can be attributed a particular time
For example "founded", "occurred", "traveled", "visited", "met" e.t.c.
Reverb wikipedia extractions are used to isolate relations that appeared with Date/day/month as object.
The jsp goes through every sentence in every doc and selects the sentence if it contains the word "I" and phrases from any of thr relations isolated in the previous step and in verb form in the sentence.
Such phrases are highlighted in the output.
Problems/conclusions
1. Most verbs are indicative of events. We would like to see or make distinction between events that last longer than a day and those on which we can put a specific calender date.
TBF

-------------------------------
Experiment - 4:
See memorystudy/entityexperiment_4.jsp
Sentences with a mention of time forms are selected and shown.
Temporal forms are recognised with Stanford's SUTime.

-------------------------------
Experiment - 5:
Normalise the dates and collect event specific words
Sort the events by number of times a date is mentioned.

-------------------------------
Experiment - 6:
If we generate list of pairs like <peron, location> or <person, organization>, it fun to solve it if two lists are shown and the user is asked to match them.
But, there is a risk of probing only semantic memory here, unless the relation can be figured out if there is an episode associated with it.
For example: Hi Richard, let meet for coffee in Coffee Aroma. <Richard, Coffee Aroma> is a good candidate as the relation is not obvious unless the user figures out the epidode.
I think its hard to enforce this constraint.

--------------------------------
Another interesting idea is to train for event phrases by looking at all the sentences with a mention of time.
Model if trained properly can then recognise sentences with no mention of date.