This package forms the core of ePADD NER. The implemented algorithm is explained in this [paper](http://vihari.github.io/personal_website/papers/xwww.pdf)

The algorithm does not follow the classic sequence labelling paradigm, but does recognition by classifying mentions. The features for classification are simple surface features. The algorithm is designed so as to avoid domain adaptability problem and for performance. 

#Quick Start Guide
##Entity Recognition

`SVMModel.loadModel(model File)` will return `SVMModel`, an instance of `NERModel`

Once a model is loaded, entities can be recognised in any free text by `NERModel.find(content)`. This method returns `Pair<Map<Short, List<String>>, List<Triple<String,Integer,Integer>>>` where the first element in the pair is a map from entity type (see `FeatureDictionary.{PERSON,ORGANIZATION,PLACE}`) to list of identified entities of this type, the second element in the pair is the list of offset for all the reognised entities irrespective of type. Note: This method returns names recognised by all the available types in the loaded model.

##Training

The trainer takes the text in the entire archive as an arguement, recognises candidate mentions in the text, consults gazette to resolve types of the mentions. A model is trained to yeild maximum score over all the candidate mentions with known types, and hence require the text from the entire archive. 

The interface for training is `train(ArchiveContent aContent, Map<String,String> externalGazette, Map<String,String> internalGazette, List<Short> types, List<String> aTypes, FeatureGenerator[] fgs, Tokenizer tokenizer, Object trainihngParams)`

Breakdown of the arguements 
+ aContent - Instance of `ArchiveContent`. It is not always feasible to pass the document content in a memory loaded data-structure.
+ externalGazette - any gazette independent of the archive like DBpedia titles which form the source of external knowledge.
+ internalGazette - a list related to the archive, if available. Like address book for email archive
+ types - List of types for which the model should be trained, type should be one of `FeatureDictionary.{PERSON,ORGANIZATION,PLACE}`
+ aTypes - allowed types for each type in the previos arguement. The types can be proper or substrings of DBpedia types like: `WrittenWork|Work`
+ fgs - Feature generators. **Only use `WordSurfaceFeature` as `ContextFeature` which is dependent on the context is experimental**. It is possible to manipulate features generated by `WordSurfaceFeature`, see the initializer: `WordSurfaceFeature(Set<String> featureTypes)`
+ tokenizer - this is the core of mention detection, right now the only available mention detector in the package is CIC (Consecutive Initial Capital) pattern based `CICTokenizer` (See the paper cited above for further details). It is possible to write your own mention detector, see `Tokenizer` interface.
+ trainingParams - Training related parameters, see `SVMModelTrainer.TrainingParam`
