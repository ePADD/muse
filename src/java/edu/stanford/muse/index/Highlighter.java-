/*
 Copyright (C) 2012 The Stanford MobiSocial Laboratory

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
 */
package edu.stanford.muse.index;

import java.util.ArrayList;
import java.util.Calendar;
import java.util.Date;
import java.util.GregorianCalendar;
import java.util.LinkedHashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.StringTokenizer;

import edu.stanford.muse.util.DictUtils;
import edu.stanford.muse.util.Util;

public class Highlighter {
	public static final int	LINES_TO_SHOW	= 100;	// lines to show by default;
													// the remaining lines are
													// hidden under a "More"
													// button. we try to not
													// show too much because
													// while jogging, an
													// ungainly scrollbar
													// appears for long pages

	/*
	 * returns doc contents, annotated with links for important terms. code is
	 * somewhat delicate. any of the input set of terms can be null in which
	 * case they are ignored. if d is non-null, points links to the internet
	 * archive version of any links, otherwise to the original link. this thing
	 * is too bloody complicated.
	 */
	public static String getHTMLAnnotatedDocumentContents(String contents, Date d, String docId,
			Set<String> stemmedTermsToHighlight, Set<String> unstemmedTermsToHighlight, Map<String, String> entitiesWithId,
			Set<String> stemmedTermsToHyperlink, Set<String> unstemmedTermsToHyperlink)
	{
		// first canonicalize everything. sorry for the long names, but the
		// logic is inherently complicated.
		// c stands for canonicalized. no worries if input is null,
		// canonicalizeMultiWordTerm will return an empty set
		// canonicalization of Entities is required.
		// unstemmedTermsToHighlight.addAll(entitiesWithId.keySet());
		// unstemmedTermsToHyperlink.addAll(entitiesWithId.keySet());

		Set<String> cStemmedTermsToHighlight = DictUtils.canonicalizeMultiWordTerms(stemmedTermsToHighlight, true);
		Set<String> cUnstemmedTermsToHighlight = DictUtils.canonicalizeMultiWordTerms(unstemmedTermsToHighlight, false);
		Set<String> cStemmedTermsToHyperlink = DictUtils.canonicalizeMultiWordTerms(stemmedTermsToHyperlink, true);
		Set<String> cUnstemmedTermsToHyperlink = DictUtils.canonicalizeMultiWordTerms(unstemmedTermsToHyperlink, false);

		// build up stemmed and unstemmed versions of prefixes that match either
		// hyperlinks or hilights
		Set<String> stemmedTermsToMatch = new LinkedHashSet<String>(), unstemmedTermsToMatch = new LinkedHashSet<String>();
		stemmedTermsToMatch.addAll(IndexUtils.computeAllPrefixes(cStemmedTermsToHighlight));
		unstemmedTermsToMatch.addAll(IndexUtils.computeAllPrefixes(cUnstemmedTermsToHighlight));
		stemmedTermsToMatch.addAll(IndexUtils.computeAllPrefixes(cStemmedTermsToHyperlink));
		unstemmedTermsToMatch.addAll(IndexUtils.computeAllPrefixes(cUnstemmedTermsToHyperlink));

		// compute the tokens generated by MyTokenizer and the corresponding
		// string index into contents that each token starts at
		// pointer[i] is an index to start of token[i]
		// nb: these include join words
		MyTokenizer tokenizer = new MyTokenizer(contents);
		List<String> tokens = new ArrayList<String>();
		List<Integer> pointers = new ArrayList<Integer>();
		while (tokenizer.hasMoreTokens())
		{
			int offset = tokenizer.getCurrentTokenPointer();
			String token = tokenizer.nextToken();
			pointers.add(offset);
			tokens.add(token.toLowerCase());
		}

		StringBuilder result = new StringBuilder();

		// now walk through the tokens, identifying longest matches in the
		// stemmed or unstemmed terms to match
		int lastTokenEmitIdx = -1;
		for (int currentIdx = 0; currentIdx < tokens.size(); currentIdx++)
		{
			// invariant: at this point, we've emit everything up to and
			// including the token lastTokenIdx.

			// now print residue between end of lastToken idx and start of
			// currentIdx, if any
			if (lastTokenEmitIdx != -1)
			{
				int residueStart = pointers.get(lastTokenEmitIdx) + tokens.get(lastTokenEmitIdx).length();
				int residueEnd = pointers.get(currentIdx); // not inclusive
				String residue = contents.substring(residueStart, residueEnd);
				result.append(Util.escapeHTML(residue));
			}
			else
			{
				// don't forget to include any residue at the beginning -- was a
				// bug earlier.
				int i = pointers.get(0);
				String residue = contents.substring(0, i);
				if (i > 0)
					result.append(Util.escapeHTML(residue));
			}

			String token = tokens.get(currentIdx);

			// special cases first:
			// if token is a link or join word, just print it and skip link
			// first (can we introduce <br/> if its too long ?)
			if (token.startsWith("http") || token.startsWith("https"))
			{
				String link = token;
				String url = link;
				if (d != null)
				{
					Calendar c = new GregorianCalendar();
					c.setTime(d);
					String archiveDate = c.get(Calendar.YEAR) + String.format("%02d", c.get(Calendar.MONTH)) + String.format("%02d", c.get(Calendar.DATE))
							+ "120000";
					url = "http://web.archive.org/web/" + archiveDate + "/" + link;
				}
				result.append("<a target=\"_blank\" href=\"" + url + "\">" + link + "</a> ");
				lastTokenEmitIdx = currentIdx;
				continue;
			}

			// join word at the beginning of a sequence, just skip
			if (DictUtils.isJoinWord(token))
			{
				// emit this token
				int startPtr = pointers.get(currentIdx);
				int endPtr = startPtr + token.length();
				result.append(contents.substring(startPtr, endPtr));
				lastTokenEmitIdx = currentIdx;
				continue;
			}

			// now look for the longest match that is present in either
			// stemmed/unstemmed terms to match
			// [matchStartTokenIdx, matchEndTokenIdx] inclusive is the token
			// with the possible match
			int matchStartTokenIdx = currentIdx, matchEndTokenIdx = currentIdx - 1;

			// matchedString is the string actually matched,
			// possibleMatch stemmed/unstemmed is one token ahead
			String possibleMatch = token.toLowerCase(), matchedString = "", matchedStringStemmed = "", matchedStringUnstemmed = ""; // matchedStringUnstemmed
																																	// is
																																	// not
																																	// the
																																	// same
																																	// as
																																	// matchedString
																																	// because
																																	// of
																																	// space
																																	// normalization
			String possibleMatchStemmed = DictUtils.canonicalizeTerm(possibleMatch, true);
			String possibleMatchUnstemmed = DictUtils.canonicalizeTerm(possibleMatch, false);

			int idx = currentIdx;
			// look forward
			do {
				if (!stemmedTermsToMatch.contains(possibleMatchStemmed) && !unstemmedTermsToMatch.contains(possibleMatchUnstemmed))
					break; // match ended, break out

				// ideally we would check for hyperlinks if this phrase is in
				// any other docs. if not, no point putting a hyperlink. but
				// this is turning out to be expensive
				// if (!isPhraseInMultipleSubDocs(possibleMatch, -1)) // note:
				// checking if phrase exists across ALL clusters. could restrict
				// to current cluster.
				// break;

				// cool. this is a good term. update our match.
				matchedString = possibleMatch;
				matchedStringStemmed = possibleMatchStemmed;
				matchedStringUnstemmed = possibleMatchUnstemmed;
				matchEndTokenIdx = idx;
				idx++;
				// skip to next non-join word token. break out if end of
				// contents reached
				while (idx < tokens.size() && DictUtils.isJoinWord(tokens.get(idx).toLowerCase()))
					idx++;
				if (idx == tokens.size())
					break;

				String nextToken = tokens.get(idx);
				possibleMatch += " " + nextToken.toLowerCase();
				possibleMatchStemmed += " " + DictUtils.canonicalizeTerm(nextToken.toLowerCase(), true);
				possibleMatchUnstemmed += " " + DictUtils.canonicalizeTerm(nextToken.toLowerCase(), false);
			} while (true);

			if (matchedString.length() == 0)
			{
				// just the first token. we can't use token directly because its
				// been lowercased
				Util.ASSERT(matchStartTokenIdx == matchEndTokenIdx + 1);
				int startPtr = pointers.get(matchStartTokenIdx);
				int endPtr = startPtr + tokens.get(matchStartTokenIdx).length();
				String textForLink = contents.substring(startPtr, endPtr);
				result.append(textForLink);
				lastTokenEmitIdx = currentIdx; // we'll reset this so we can
												// reread the last token 'cos it
												// didn't match
				continue;
			}

			// good, there was some match.
			// textForLink goes from beginning of first token to end of last
			// token
			// not the same as matchedString because that may have been
			// normalized, better to read from the original source.
			int textForSpanStart = pointers.get(matchStartTokenIdx);
			int textForSpanEnd = pointers.get(matchEndTokenIdx) + tokens.get(matchEndTokenIdx).length();
			String html = contents.substring(textForSpanStart, textForSpanEnd);

			// insert a highlight or hyperlink, or both
			if (cUnstemmedTermsToHighlight != null && cUnstemmedTermsToHighlight.contains(matchedStringUnstemmed)
					|| cStemmedTermsToHighlight.contains(matchedStringStemmed)) {
				html = "<span title=\"Click to see more messages with this term\" class=\"hilitedTerm rounded\">" + html + "</span>"; // this
																																		// is
																																		// not
																																		// strictly
																																		// a
																																		// facet,
																																		// but
																																		// the
																																		// UI
																																		// behaves
																																		// like
																																		// class
																																		// facet
			}

			if (cUnstemmedTermsToHyperlink.contains(matchedStringUnstemmed) || cStemmedTermsToHyperlink.contains(matchedStringStemmed))
			{
				String link = "browse?term=&quot;" + Util.escapeHTML(matchedString) + "&quot;";
				// note &quot here because the quotes have to survive through
				// the html page and reflect back in the URL
				link += "&initDocId=" + docId; // may need to URI escape docId?
												// I think it's nice to
												// initialize the new view at
												// the same message
				String style = "", cls="";

				String title = "";
				if (!entitiesWithId.containsKey(matchedString))
					title = "Click to see more matches of this term.";
				else {
					if (entitiesWithId.get(matchedString) == null) {
						title = "Unresolved entity";
						style = "";
					} else {
						title = "<div id=\"fast_\"" + entitiesWithId.get(matchedString) + "></div>";
						title += "<script>getFastData(\"" + entitiesWithId.get(matchedString) + "\")</script>";
					}
				}
				html = " <a class=\"no-underline\" style=\"" + style + "\" title=\"" + title + "\">" + html + "</a> ";
			}

			result.append(html);
			lastTokenEmitIdx = matchEndTokenIdx;
			currentIdx = lastTokenEmitIdx; // adjust loop idx, so we pick up in
											// the next iteration with the next
											// token
		}

		// this is the final residue
		if (lastTokenEmitIdx != -1)
		{
			int residueStart = pointers.get(lastTokenEmitIdx) + tokens.get(lastTokenEmitIdx).length();
			int residueEnd = contents.length(); // not inclusive
			String residue = contents.substring(residueStart, residueEnd);
			result.append(Util.escapeHTML(residue));
		}

		// replace newlines by <br/>
		StringTokenizer st = new StringTokenizer(result.toString(), "\n");
		StringBuilder htmlResult = new StringBuilder();
		int lineCount = 0;
		boolean overflow = false;
		while (st.hasMoreTokens())
		{
			String line = st.nextToken();
			/*
			 * if (++lineCount == LINES_TO_SHOW) // cut off beyond the line
			 * limit lines { overflow = true;
			 * htmlResult.append("<div style=\"display:none;margin:0px;\">\n");
			 * }
			 */
			htmlResult.append(line);
			htmlResult.append("\n<br/>");
		}
		if (overflow)
		{
			htmlResult.append("</div>\n");
			// the nojog class ensures that the jog doesn't pop up when the more
			// button is clicked
			htmlResult
					.append("<span class=\"nojog\" style=\"color:#500050;text-decoration:underline;font-size:12px\" onclick=\"muse.reveal(this, false);\">More</span><br/>\n");
		}
		String strResult = htmlResult.toString();

		// Highlight by regex search.
		// TODO: should take a separate set that represents the regex patterns
		// rather than reusing unstemmedTermsToHighlight
		if (!Util.nullOrEmpty(unstemmedTermsToHighlight)) {
			strResult = strResult.replaceAll(Util.join(unstemmedTermsToHighlight, "|"), "<span class='hilitedTerm rounded'>$0</span>");
		}

		// couldn't figure out what MyTokeniser is doing.
		if (entitiesWithId != null) {
			for (String entity : entitiesWithId.keySet()) {
				String link = "browse?term=&quot;" + Util.escapeHTML(entity) + "&quot;";
				// note &quot here because the quotes have to survive through
				// the html page and reflect back in the URL
				link += "&initDocId=" + docId; // may need to URI escape docId?
												// I think it's nice to
												// initialize the new view at
												// the same message
				String style = "";

				String title = "";
				if (entitiesWithId.get(entity) == null) {
					title = "Unresolved entity";
//					style = "color: red";
				} else {
					title = "<div id=\"fast_" + entitiesWithId.get(entity) + "\"></div>";
					title += "<script>getFastData(\"" + entitiesWithId.get(entity) + "\");</script>";
					style = "color:green";
				}

				String html = " <a class=\"no-underline\" style=\"" + style + "\" title='" + title + "' href='" + link + "'>" + entity + "</a> ";
				strResult = strResult.replaceAll("\\W(?i)" + entity+"\\W", html);
			}
		}
		return strResult;
	}

	public static void main(String args[])
	{
		String test = "... ....... .. ... ....\n....://.......:..../........./......../?...=...\n... ...\n* .... ...... .... ....... .. .. ......... ... ......... ....\n......... ..../...../......... ....... .. .... .... ... ......\n......,foobar";
		String s = getHTMLAnnotatedDocumentContents(test, new Date(), "docid", null, null, null, null, null);
		System.out.println(s);
	}
}
